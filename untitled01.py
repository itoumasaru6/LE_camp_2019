# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GCkFf8GvatLRrANpVXvTqpqJg298YCPI
"""

# coding-utf8

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

from keras.utils import to_categorical
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import RMSprop
from keras.datasets import mnist

print(tf.__version__)

# データセットの
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

print("train_images", type(train_images))
print("train_labels", type(train_labels))
print("test_images", type(test_images))
print("test_labels", type(test_labels))

num_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

print(train_images.shape)
print(test_images.shape)

train_images = train_images.reshape(60000, 784)
test_images = test_images.reshape(10000, 784)

print(train_images.shape)
print(test_images.shape)

train_images = train_images.astype('float32')
test_images = test_images.astype('float32')

train_images /= 255
test_images /= 255

train_label = keras.utils.to_categorical(train_labels, len(num_classes))
test_label = keras.utils.to_categorical(test_labels, len(num_classes))


# データの前処理
train_imgs = train_images.reshape(60000, 28, 28)
plt.figure()
plt.imshow(train_imgs[0])
plt.colorbar()
plt.grid(False)
#plt.show()

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_imgs[i], cmap=plt.cm.binary)
    plt.xlabel(num_classes[train_labels[i]])
#plt.show()

print(1)
# モデルの構築
# 層の設定
# 1:28*28の２次元配列を786の１次元配列に変換
# 2:ネットワークの１層目は128個のニューロン
# 3:ネットワークの最後の層は10のノードのsoftmax層。合計が1になる10個の配列を返しどれに属するか確率を出力する。
model  = Sequential()
model.add(Dense(512, activation= 'relu', input_shape = (784,)))
model.add(Dropout(0.2))
model.add(Dense(512,activation= 'relu')) 
model.add(Dropout(0.2))
model.add(Dense(len(num_classes), activation = 'softmax'))
model.summary()


# モデルのコンパイル
# model.compile(optimize='adam',
#               loss='sparse_categorical_crossentropy',
#               metrics=['accuracy'])
model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.0005), metrics=['accuracy'])

history = model.fit(train_images, train_label
                   , batch_size = 128
                    , epochs = 10
                    , verbose = 1
                    , validation_data=(test_images, test_label))


history_df = pd.DataFrame(history.history)
history_df[['loss', 'val_loss']].plot()
history_df[['acc', 'val_acc']].plot()
# モデルの訓練
# model.fit(train_images, train_label, epochs=5)

# 正解率の評価
# test_loss, test_acc = model.evaluate(test_images, test_label, verbose=2)

# print('¥nTset accyracy:', test_acc)

# 予測する
prediction = model.predict(test_images)

prediction[0]

np.argmax(prediction[0])

test_labels[0]

